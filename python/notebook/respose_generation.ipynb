{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reload the data and try again\n",
    "import torch\n",
    "import pandas as pd\n",
    "from extended_function import *\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"../data/combine_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and prepare data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model...\n",
      "\n",
      "Model Load Completed\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "print(\"\\nLoading model...\")\n",
    "model = torch.load(\"../model/model_25epochs.pth\", weights_only=False)\n",
    "print(\"\\nModel Load Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df['service'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict intent using the BERT model\n",
    "def predict_intent_bert(text):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=64,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "        predicted_label = label_encoder.inverse_transform([predicted.cpu().item()])[0]\n",
    "        \n",
    "    # return predicted_label, confidence.cpu().item()\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_db = extract_conversation_pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_message, intent, entities=None):\n",
    "    \"\"\"Generate a response using similar conversations and custom formatting\"\"\"\n",
    "    # Find similar conversations\n",
    "    similar_convs = find_similar_conversation(user_message, intent, conversation_db)\n",
    "    \n",
    "    if not similar_convs:\n",
    "        return f\"I understand this is a {intent.replace('_', ' ')}. Could you please provide more details?\"\n",
    "    \n",
    "    # Get the most similar conversation's response\n",
    "    best_response = similar_convs[-1]['bot_response']\n",
    "    \n",
    "    # Create a structured response\n",
    "    response = f\"I understand your {intent.replace('_', ' ')}. \"\n",
    "    response += best_response + \"\\n\\n\"\n",
    "    \n",
    "    # Add specific requirements based on intent\n",
    "    if intent == 'training_request':\n",
    "        response += \"Please provide:\\n- Number of participants\\n- Preferred dates\\n- Specific topics\\n- Budget constraints\"\n",
    "    elif intent == 'it_issue_report':\n",
    "        response += \"To help resolve this quickly, please share:\\n- Device details\\n- Error messages\\n- When the issue started\\n- Steps already taken\"\n",
    "    elif intent == 'access_request':\n",
    "        response += \"To process your request, I need:\\n- System/application name\\n- Required access level\\n- Business justification\\n- Manager approval\"\n",
    "    elif intent == 'time_off_report':\n",
    "        response += \"Please confirm:\\n- Exact dates\\n- Type of leave\\n- Handover plan\"\n",
    "    \n",
    "    # Add entity-specific responses if available\n",
    "    if entities:\n",
    "        try:\n",
    "            entities_dict = json.loads(entities.replace(\"'\", '\"')) if isinstance(entities, str) else entities\n",
    "            if 'training_topic' in entities_dict:\n",
    "                response += f\"\\n\\nI see you're interested in {entities_dict['training_topic']} training.\"\n",
    "            if 'issue_type' in entities_dict:\n",
    "                response += f\"\\n\\nI understand you're experiencing {entities_dict['issue_type']} issues.\"\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Response Generator Examples:\n",
      "----------------------------------------------------------------------\n",
      "User: I need to arrange machine learning training for my team on topic machine learning\n",
      "Bot: I understand your training request. Certainly, improving your skills is important. What kind of outcomes are you hoping to achieve through the training?', \"That's a great goal to have. Do you have an estimated budget in mind for the training?\n",
      "\n",
      "Please provide:\n",
      "- Number of participants\n",
      "- Preferred dates\n",
      "- Specific topics\n",
      "- Budget constraints\n",
      "\n",
      "I see you're interested in machine learning training.\n",
      "----------------------------------------------------------------------\n",
      "User: My laptop keeps crashing every time I open email\n",
      "Bot: I understand your it issue report. No problem, can you tell me a bit more about what's going on so I can try to help resolve it?\n",
      "\n",
      "To help resolve this quickly, please share:\n",
      "- Device details\n",
      "- Error messages\n",
      "- When the issue started\n",
      "- Steps already taken\n",
      "\n",
      "I understand you're experiencing system_crash issues.\n",
      "----------------------------------------------------------------------\n",
      "User: I'd like to request vacation days for next month\n",
      "Bot: I understand your time off report. No problem, what kind of time are you looking to take? A vacation maybe? How many days will you need total?', \"Got it. Can you let me know what you have planned for your time off? You don't have to give details if you don't want to. Also, when would you like your vacation to start? Just give me the date.\", 'Okay, and when do you plan to return? Go ahead and give me the return date too please.', \"Great, have you made arrangements for someone to cover your work while you're gone? If so, who will be helping out?\n",
      "\n",
      "Please confirm:\n",
      "- Exact dates\n",
      "- Type of leave\n",
      "- Handover plan\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the response generator\n",
    "print(\"Advanced Response Generator Examples:\")\n",
    "print(\"-\" * 70)\n",
    "test_cases = [\n",
    "    (\"I need to arrange machine learning training for my team\",  \n",
    "     {'training_topic': 'machine learning', 'number_of_participants': '5'}),\n",
    "    (\"My laptop keeps crashing every time I open email\", \n",
    "     {'issue_type': 'system_crash', 'affected_application': 'email'}),\n",
    "    (\"I'd like to request vacation days for next month\", \n",
    "     {'leave_type': 'vacation', 'dates': 'next month'})\n",
    "]\n",
    "\n",
    "for message, entities in test_cases:\n",
    "    print(f\"User: {message}\")\n",
    "    predicted_intent = predict_intent_bert(message)\n",
    "    response = generate_response(message, predicted_intent, entities)\n",
    "    print(f\"Bot: {response}\")\n",
    "    print(\"-\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

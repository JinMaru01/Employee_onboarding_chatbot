{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ab7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/combine_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88639bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create NER datasets\n",
    "def create_ner_datasets(df):\n",
    "    for service in df['service'].unique():\n",
    "        service_df = df[df['service'] == service]\n",
    "        ner_data = []\n",
    "        \n",
    "        for _, row in service_df.iterrows():\n",
    "            # Replace single quotes with double quotes\n",
    "            entities_str = row['entities'].replace(\"'\", '\"')\n",
    "            \n",
    "            try:\n",
    "                entities = json.loads(entities_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue  # Skip this row if JSON is invalid\n",
    "                \n",
    "            tokens = []\n",
    "            \n",
    "            # Extract entities for labeling\n",
    "            for key, value in entities.items():\n",
    "                tokens.append((value, key))  # (text, label)\n",
    "                \n",
    "            ner_data.append(tokens)\n",
    "\n",
    "        # Save to file named after the service\n",
    "        with open(f\"../../data/ner_dataset/{service}_ner_dataset.txt\", \"w\") as file:\n",
    "            for entry in ner_data:\n",
    "                file.write(f\"{entry}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NER datasets\n",
    "create_ner_datasets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sample data from your dataset\n",
    "data = [\n",
    "    [('required for my job responsibilities', 'purpose_of_access')],\n",
    "]\n",
    "\n",
    "def convert_to_bio_format(data):\n",
    "    bio_data = []\n",
    "    \n",
    "    for entry in data:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        \n",
    "        for text, label in entry:\n",
    "            # Split the text into tokens\n",
    "            token_list = text.split()  # Basic tokenization\n",
    "            \n",
    "            # Create BIO labels\n",
    "            for i, token in enumerate(token_list):\n",
    "                if i == 0:\n",
    "                    labels.append(f'B-{label}')  # Beginning of an entity\n",
    "                else:\n",
    "                    labels.append(f'I-{label}')  # Inside an entity\n",
    "            \n",
    "            tokens.extend(token_list)\n",
    "\n",
    "        # Combine tokens and labels\n",
    "        bio_entry = list(zip(tokens, labels))\n",
    "        bio_data.append(bio_entry)\n",
    "\n",
    "    return bio_data\n",
    "\n",
    "# Convert the data\n",
    "bio_formatted_data = convert_to_bio_format(data)\n",
    "\n",
    "# Save to a file or print\n",
    "with open('ner_training_data.json', 'w') as f:\n",
    "    json.dump(bio_formatted_data, f, indent=2)\n",
    "\n",
    "# Example output\n",
    "for entry in bio_formatted_data:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7af9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08318673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

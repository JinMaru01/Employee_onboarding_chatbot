{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d08fb8a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import random\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c592c",
   "metadata": {},
   "source": [
    "### Convert JSON to Spacy Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spacy_format(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    training_data = []\n",
    "    for item in data:\n",
    "        text = item[\"content\"]\n",
    "        entities = [(ent[\"start\"], ent[\"end\"], ent[\"label\"]) for ent in item[\"entities\"]]\n",
    "        training_data.append((text, {\"entities\": entities}))\n",
    "    \n",
    "    return training_data\n",
    "filepath = \"../../data/all_intents_ner.json\"\n",
    "spacy_data = convert_to_spacy_format(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ebf17",
   "metadata": {},
   "source": [
    "### Remove Overlap Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overlapping_entities(entities):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for start, end, label in entities:\n",
    "        key = (start, end)\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            result.append((start, end, label))\n",
    "    return result\n",
    "\n",
    "# Apply to your data\n",
    "cleaned_data = []\n",
    "for text, annots in spacy_data:\n",
    "    cleaned_ents = remove_overlapping_entities(annots[\"entities\"])\n",
    "    cleaned_data.append((text, {\"entities\": cleaned_ents}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cf584",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b281e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3395e321",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")  # create blank English model\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels\n",
    "for _, annotations in cleaned_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Train the model\n",
    "nlp.begin_training()\n",
    "for itn in range(30):  # number of iterations\n",
    "    random.shuffle(cleaned_data)\n",
    "    losses = {}\n",
    "    batches = minibatch(cleaned_data, size=2)\n",
    "    for batch in batches:\n",
    "        examples = []\n",
    "        for text, annots in batch:\n",
    "            examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "        nlp.update(examples, losses=losses)\n",
    "    print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19edbb97",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de8e2fc",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca219ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ner_model\")\n",
    "\n",
    "doc = nlp(\"training topic: machine learning. number of participants: Three.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
